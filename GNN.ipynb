{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the simulation has been run and the logs have been saved, we can load the loads and extract the data needed for training the Graph Convolutional Net in the tracker. The data is stored in such way that it can be loaded by pytorch-geometric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from python.tracker import Tracker\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "data_list = [Data(...), ..., Data(...)]\n",
    "loader = DataLoader(data_list, batch_size=32)\n",
    "\n",
    "\n",
    "with open(filename, 'rb') as f:\n",
    "    sim_log = pickle.load(f)\n",
    "sim_state = sim_log['sim_state']\n",
    "\n",
    "\n",
    "from python.constants import GRAPH_PATH\n",
    "import json\n",
    "\n",
    "# load graph\n",
    "with open(GRAPH_PATH, 'rb') as f:\n",
    "    graph_data = json.load(f)\n",
    "nodes = graph_data['nodes']\n",
    "edges = graph_data['edges']\n",
    "\n",
    "robot_observations = []\n",
    "for i in range(len(sim_state)-1):\n",
    "    probabilities, confidences = Tracker.extract_observation_from_state(sim_state[0])\n",
    "    next_probabilities, next_confidences = Tracker.extract_observation_from_state(sim_state[1])\n",
    "\n",
    "    robot_observations.append(Data(\n",
    "        # x=torch.hstack((torch.tensor(probabilities[:,np.newaxis]), torch.tensor(confidences[:,np.newaxis]))), \n",
    "        x=torch.tensor(probabilities[:,np.newaxis]),\n",
    "        y=torch.tensor(next_probabilities[:,np.newaxis]),\n",
    "        edge_index=torch.tensor(edges).T)\n",
    "        )\n",
    "\n",
    "loader = DataLoader(robot_observations, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a DataLoader for our data, we can define our network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        # Define your layers here\n",
    "        self.conv1 = GCNConv(1, 8)\n",
    "        self.conv2 = GCNConv(8, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "          \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.47653289093650963\n",
      "Epoch 2, Loss: 0.2267185828429523\n",
      "Epoch 3, Loss: 0.16100687461671984\n",
      "Epoch 4, Loss: 0.13177482895166961\n",
      "Epoch 5, Loss: 0.09415652318789017\n",
      "Epoch 6, Loss: 0.06902463443930916\n",
      "Epoch 7, Loss: 0.06070562598813252\n",
      "Epoch 8, Loss: 0.05616342912459074\n",
      "Epoch 9, Loss: 0.05224546466573497\n",
      "Epoch 10, Loss: 0.043209311606710994\n",
      "Epoch 11, Loss: 0.02904659745410954\n",
      "Epoch 12, Loss: 0.022102839624904502\n",
      "Epoch 13, Loss: 0.017662046813551883\n",
      "Epoch 14, Loss: 0.01403605539617939\n",
      "Epoch 15, Loss: 0.012278992077056263\n",
      "Epoch 16, Loss: 0.011746225032124174\n",
      "Epoch 17, Loss: 0.011566076423633437\n",
      "Epoch 18, Loss: 0.011496834899972056\n",
      "Epoch 19, Loss: 0.011461851064601495\n",
      "Epoch 20, Loss: 0.011440883968299814\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        data.x = data.x.float()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is trained and can be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire model saved to gcn_model_full.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'models/gcn_model_full.pth')\n",
    "print('Entire model saved to gcn_model_full.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
